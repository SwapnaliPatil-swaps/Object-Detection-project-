{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "net = cv2.dnn.readNet(\"yolov3.weights\",\"yolo_V3.cfg\")\n",
    "# using opencv readnetfunction read the wightsa nd cfg\n",
    "\n",
    "classes =[]\n",
    "#to store the coco names\n",
    "with open(\"coco.names\",\"r\") as f:\n",
    "\tclasses = f.read().splitlines()\n",
    "#read and split the coco names\n",
    "cap =cv2.VideoCapture(\"video_file.mp4\")\n",
    "#read the image file\n",
    "while True:\n",
    "    _,img = cap.read()\n",
    "    height, width, _ = img.shape \n",
    "    cv2.imshow(\"Image\",img)\n",
    "    # to show the image\n",
    "\n",
    "    blob = cv2.dnn.blobFromImage(img, 1/255, (416,416),(0,0,0), swapRB = True, crop =False )\n",
    "    \"\"\"\n",
    "    The input to the network is a so-called blob object. The function cv.dnn.blobFromImage(img, scale, size, mean) \n",
    "    transforms the image into a blob:\n",
    "    It has the following parameters:\n",
    "\n",
    "    1.the image to transform\n",
    "    2.the scale factor (1/255 to scale the pixel values to [0..1])\n",
    "    3.the size, here a 416x416 square image\n",
    "    4.the mean value (default=0)\n",
    "    5.the option swapBR=True (since OpenCV uses BGR)\n",
    "    \"\"\"\n",
    "    net.setInput(blob)\n",
    "    # set the input as blob to the network\n",
    "\n",
    "    output_layers_names = net.getUnconnectedOutLayersNames()\n",
    "    #to get only output layers names to pass into output_layers_names\n",
    "\n",
    "    layerOutputs = net.forward(output_layers_names)\n",
    "    #run the forward pass and obtain the output layers\n",
    "\n",
    "    boxes = []\n",
    "    # to get the bounding box list\n",
    "    confidences = []\n",
    "    # confidence list to saw the confidence\n",
    "    class_ids = []\n",
    "    # class id list\n",
    "\n",
    "# contains 4 bounding box offsets, 80 class prediction , 1 confidence total 85 pararmeters , you can consider first 4 as location(corners),after 5 predictions started up to 80\n",
    "    for output in layerOutputs:\n",
    "        for detection in output:\n",
    "            scores = detection[5:] # crate array to store score \n",
    "            class_id = np.argmax(scores) #location of highest score location\n",
    "            confidence = scores[class_id] #to store highest prediction score\n",
    "            \n",
    "            if confidence > 0.5: # checks the confidence and plot BB\n",
    "                center_x = int(detection[0]*width) # x,y cordinates of the center of the object\n",
    "                center_y = int(detection[1]*height)\n",
    "                w = int(detection[2]*width) # w, h is width and height bounding box \n",
    "                h = int(detection[3]*height)\n",
    "\n",
    "                x = int(center_x - w/2) # center_x is image center minus w/2 width is bounding box \n",
    "                y = int(center_y - h/2) # center_y is image center minus h/2 height is bounding box \n",
    "            \n",
    "                boxes.append([x,y,w,h]) # append the bounding box cordinates into list boxes\n",
    "                confidences.append((float(confidence))) #append the confidence\n",
    "                class_ids.append(class_id)# append the class ids\n",
    "\n",
    "            \n",
    "    print(len(boxes))\n",
    "    indexes = cv2.dnn.NMSBoxes(boxes, confidences,0.5,0.4) # non maximum suppresion is use for to eliminate another boxes\n",
    "    font = cv2.FONT_HERSHEY_PLAIN\n",
    "    colors = np.random.uniform(0, 255, size =(len(boxes),3))\n",
    "    if len(indexes) > 0:\n",
    "        for i in indexes.flatten(): #Return a copy of the array collapsed into one dimension array.\n",
    "            x,y,w,h = boxes[i]\n",
    "            label = str(classes[class_ids[i]])\n",
    "            confidence = str(round(confidences[i],2)) #round(number, number of digits)\n",
    "            color = colors[i]\n",
    "            cv2.rectangle(img,(x,y), (x+w, y+h), color, 2) # syntax: cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "            cv2.putText(img, label + \" \"+ confidence, (x, y+20), font, 2, (255,255,255), 2) #Syntax: cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "\n",
    "    \"\"\"\n",
    "    syntax: cv2.rectangle(image, start_point, end_point, color, thickness)\n",
    "\n",
    "    Parameters:\n",
    "    image: It is the image on which rectangle is to be drawn.\n",
    "    start_point: It is the starting coordinates of rectangle. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).\n",
    "    end_point: It is the ending coordinates of rectangle. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).\n",
    "    color: It is the color of border line of \n",
    "    \"\"\"\n",
    "    \"\"\"\n",
    "    Syntax: cv2.putText(image, text, org, font, fontScale, color[, thickness[, lineType[, bottomLeftOrigin]]])\n",
    "\n",
    "    Parameters:\n",
    "    image: It is the image on which text is to be drawn.\n",
    "    text: Text string to be drawn.\n",
    "    org: It is the coordinates of the bottom-left corner of the text string in the image. The coordinates are represented as tuples of two values i.e. (X coordinate value, Y coordinate value).\n",
    "    font: It denotes the font type. Some of font types are FONT_HERSHEY_SIMPLEX, FONT_HERSHEY_PLAIN, , etc.\n",
    "    fon\n",
    "    (255, 0, 0) for blue color.\n",
    "    \"\"\"\n",
    "    cv2.imshow('Image',img)\n",
    "    key = cv2.waitKey(1)#cv2 waitkey() allows you to wait for a specific time in milliseconds until you press any button on the keyword. \n",
    "        # delay of photo display\n",
    "\n",
    "    # default as infinite time\n",
    "    if key == 27: # Esc key to stop\n",
    "         break\n",
    "            \n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
